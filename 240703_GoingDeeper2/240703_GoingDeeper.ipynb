{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "as8XcGTbcE8Y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "import sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.naive_bayes import ComplementNB, MultinomialNB #다항분포 나이브 베이즈 모델\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Embedding, InputLayer, Dropout, BatchNormalization, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실험 설계\n",
        "\n",
        "**num_words = [10000, 20000, max(30979+3)], with tokens**  \n",
        "**models = [LogisticRegression, 그래디언트 부스팅 트리, 보팅]**\n",
        "\n",
        "\n",
        "## 평가 기준\n",
        "\n",
        "### 1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가?\n",
        "  * 3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.\n",
        "  \n",
        "### 2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가?\n",
        "  * Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.  \n",
        "  \n",
        "### 3. 딥러닝 모델을 활용해 성능이 비교 및 확인되었는가?\n",
        "  * 동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.  "
      ],
      "metadata": {
        "id": "og3UyTIXcLld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
        "    df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
        "    plt.ylabel('label')\n",
        "    plt.xlabel('predicted value')"
      ],
      "metadata": {
        "id": "Jd6K3JzkcKID"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(num_words=None):\n",
        "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
        "    word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "    index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "\n",
        "    for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "        index_to_word[index]=token\n",
        "\n",
        "    decoded = []\n",
        "    for i in range(len(x_train)):\n",
        "        t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "        decoded.append(t)\n",
        "\n",
        "    x_train = decoded\n",
        "\n",
        "    decoded = []\n",
        "    for i in range(len(x_test)):\n",
        "        t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "        decoded.append(t)\n",
        "\n",
        "    x_test = decoded\n",
        "\n",
        "    dtmvector = CountVectorizer()\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "    # 데이터를 DTM으로 변환 -> DTM을 TF-IDF 행렬로 변환\n",
        "    x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "    tfidfv_train = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "\n",
        "    x_test_dtm = dtmvector.transform(x_test)\n",
        "    tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "\n",
        "    return tfidfv_train, y_train, tfidfv_test, y_test"
      ],
      "metadata": {
        "id": "NnPMSZLKcNvW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_models(num_words=None):\n",
        "    x_train, y_train, x_test, y_test = load_data(num_words=num_words)\n",
        "\n",
        "    # 1.Logistic Regression\n",
        "    lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
        "    lr.fit(x_train, y_train)\n",
        "\n",
        "    predicted_lr = lr.predict(x_test)\n",
        "    print(\"--\"*10 + \"Logistic Regression\" + \"--\"*10)\n",
        "    print(\"Logistic Regression 정확도:\", accuracy_score(y_test, predicted_lr))\n",
        "\n",
        "    print(classification_report(y_test, predicted_lr, zero_division=0))\n",
        "    print(\"---\"*10+\"\\n\")\n",
        "\n",
        "    # 2.Linear SVC\n",
        "    lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
        "    lsvc.fit(x_train, y_train)\n",
        "\n",
        "    predicted_lsvc = lsvc.predict(x_test)\n",
        "    print(\"--\"*10 + \"Linear SVC\" + \"--\"*10)\n",
        "    print(\"정확도:\", accuracy_score(y_test, predicted_lsvc))\n",
        "\n",
        "    print(classification_report(y_test, predicted_lsvc, zero_division=0))\n",
        "    print(\"---\"*10+\"\\n\")\n",
        "\n",
        "    # 3.Voting(Logistic Regression, Complement Naive Bayes Classifier, GradientBoosting Classifier)\n",
        "    # 각 개별 모델 선언\n",
        "    logistic_regression = LogisticRegression(penalty='l2', random_state=0)\n",
        "    complement_nb = ComplementNB()\n",
        "    gradient_boosting = GradientBoostingClassifier(random_state=0)\n",
        "\n",
        "    # VotingClassifier 선언\n",
        "    voting_classifier = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('logistic', logistic_regression),\n",
        "            ('complement_nb', complement_nb),\n",
        "            ('gradient_boosting', gradient_boosting)\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "\n",
        "    voting_classifier.fit(x_train, y_train)\n",
        "\n",
        "    predicted_voting = voting_classifier.predict(x_test)\n",
        "    print(\"--\"*10 + \"Voting Classifier\" + \"--\"*10)\n",
        "    print(\"정확도:\", accuracy_score(y_test, predicted_voting))\n",
        "\n",
        "    print(classification_report(y_test, predicted_voting, zero_division=0))\n",
        "    print(\"---\"*10+\"\\n\")"
      ],
      "metadata": {
        "id": "eNlbya74cO72"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_models(num_words=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggVbqkfteEJ-",
        "outputId": "d52449fd-53de-48fe-cb4c-20f6c5d4fc40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 0s 0us/step\n",
            "--------------------Logistic Regression--------------------\n",
            "Logistic Regression 정확도: 0.8107747105966162\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.74      0.78      0.76       105\n",
            "           2       0.70      0.70      0.70        20\n",
            "           3       0.91      0.93      0.92       813\n",
            "           4       0.80      0.87      0.84       474\n",
            "           5       1.00      0.20      0.33         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.68      0.71      0.69        38\n",
            "           9       0.81      0.88      0.85        25\n",
            "          10       0.93      0.87      0.90        30\n",
            "          11       0.67      0.72      0.70        83\n",
            "          12       0.62      0.38      0.48        13\n",
            "          13       0.65      0.59      0.62        37\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.80      0.44      0.57         9\n",
            "          16       0.70      0.77      0.73        99\n",
            "          17       0.80      0.67      0.73        12\n",
            "          18       0.81      0.65      0.72        20\n",
            "          19       0.69      0.71      0.70       133\n",
            "          20       0.60      0.49      0.54        70\n",
            "          21       0.71      0.81      0.76        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.64      0.75      0.69        12\n",
            "          24       0.62      0.53      0.57        19\n",
            "          25       0.88      0.68      0.76        31\n",
            "          26       1.00      0.88      0.93         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.67      0.40      0.50        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       1.00      0.58      0.74        12\n",
            "          31       0.78      0.54      0.64        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.45      0.45      0.45        11\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.50      0.40      0.44         5\n",
            "          40       0.75      0.30      0.43        10\n",
            "          41       0.75      0.38      0.50         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.86      1.00      0.92         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.81      2246\n",
            "   macro avg       0.79      0.63      0.67      2246\n",
            "weighted avg       0.81      0.81      0.81      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Linear SVC--------------------\n",
            "정확도: 0.7845057880676759\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.74      0.74      0.74       105\n",
            "           2       0.57      0.65      0.60        20\n",
            "           3       0.91      0.91      0.91       813\n",
            "           4       0.80      0.84      0.82       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.86      0.86      0.86        14\n",
            "           7       0.50      0.33      0.40         3\n",
            "           8       0.66      0.71      0.68        38\n",
            "           9       0.77      0.80      0.78        25\n",
            "          10       0.92      0.77      0.84        30\n",
            "          11       0.66      0.77      0.71        83\n",
            "          12       0.38      0.38      0.38        13\n",
            "          13       0.62      0.57      0.59        37\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.62      0.56      0.59         9\n",
            "          16       0.62      0.71      0.66        99\n",
            "          17       0.71      0.42      0.53        12\n",
            "          18       0.80      0.60      0.69        20\n",
            "          19       0.63      0.63      0.63       133\n",
            "          20       0.51      0.41      0.46        70\n",
            "          21       0.56      0.70      0.62        27\n",
            "          22       0.20      0.14      0.17         7\n",
            "          23       0.60      0.75      0.67        12\n",
            "          24       0.69      0.58      0.63        19\n",
            "          25       0.92      0.71      0.80        31\n",
            "          26       0.88      0.88      0.88         8\n",
            "          27       1.00      0.50      0.67         4\n",
            "          28       0.57      0.40      0.47        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       0.75      0.50      0.60        12\n",
            "          31       0.89      0.62      0.73        13\n",
            "          32       1.00      0.90      0.95        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.57      0.57      0.57         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.62      0.45      0.53        11\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.75      0.60      0.67         5\n",
            "          40       0.25      0.20      0.22        10\n",
            "          41       0.83      0.62      0.71         8\n",
            "          42       1.00      0.33      0.50         3\n",
            "          43       0.55      1.00      0.71         6\n",
            "          44       0.80      0.80      0.80         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.78      2246\n",
            "   macro avg       0.70      0.63      0.64      2246\n",
            "weighted avg       0.79      0.78      0.78      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Voting Classifier--------------------\n",
            "정확도: 0.7969723953695459\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.75      0.78        12\n",
            "           1       0.76      0.72      0.74       105\n",
            "           2       0.78      0.70      0.74        20\n",
            "           3       0.91      0.93      0.92       813\n",
            "           4       0.78      0.88      0.82       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.80      0.86      0.83        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.69      0.66      0.68        38\n",
            "           9       0.81      0.84      0.82        25\n",
            "          10       0.90      0.87      0.88        30\n",
            "          11       0.66      0.71      0.68        83\n",
            "          12       0.33      0.46      0.39        13\n",
            "          13       0.71      0.65      0.68        37\n",
            "          14       0.14      0.50      0.22         2\n",
            "          15       0.43      0.33      0.38         9\n",
            "          16       0.78      0.76      0.77        99\n",
            "          17       0.33      0.33      0.33        12\n",
            "          18       0.67      0.50      0.57        20\n",
            "          19       0.71      0.69      0.70       133\n",
            "          20       0.72      0.47      0.57        70\n",
            "          21       0.71      0.81      0.76        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.54      0.58      0.56        12\n",
            "          24       0.63      0.63      0.63        19\n",
            "          25       0.95      0.58      0.72        31\n",
            "          26       0.75      0.75      0.75         8\n",
            "          27       0.50      0.50      0.50         4\n",
            "          28       0.43      0.30      0.35        10\n",
            "          29       0.25      0.75      0.38         4\n",
            "          30       0.50      0.42      0.45        12\n",
            "          31       0.83      0.38      0.53        13\n",
            "          32       1.00      0.90      0.95        10\n",
            "          33       0.75      0.60      0.67         5\n",
            "          34       1.00      0.57      0.73         7\n",
            "          35       1.00      0.67      0.80         6\n",
            "          36       0.62      0.45      0.53        11\n",
            "          37       0.67      1.00      0.80         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.67      0.40      0.50         5\n",
            "          40       0.50      0.10      0.17        10\n",
            "          41       0.62      0.62      0.62         8\n",
            "          42       0.67      0.67      0.67         3\n",
            "          43       0.67      0.67      0.67         6\n",
            "          44       0.67      0.80      0.73         5\n",
            "          45       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.80      2246\n",
            "   macro avg       0.66      0.60      0.60      2246\n",
            "weighted avg       0.80      0.80      0.79      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_models(num_words=20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDotmO85fRE7",
        "outputId": "e9ae4cd7-f618-4f68-d5f9-928f070ec2fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 0s 0us/step\n",
            "--------------------Logistic Regression--------------------\n",
            "Logistic Regression 정확도: 0.8147818343722173\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.73      0.79      0.76       105\n",
            "           2       0.78      0.70      0.74        20\n",
            "           3       0.92      0.93      0.92       813\n",
            "           4       0.80      0.88      0.84       474\n",
            "           5       1.00      0.20      0.33         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.69      0.71      0.70        38\n",
            "           9       0.85      0.88      0.86        25\n",
            "          10       0.96      0.87      0.91        30\n",
            "          11       0.68      0.72      0.70        83\n",
            "          12       0.62      0.38      0.48        13\n",
            "          13       0.65      0.65      0.65        37\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.80      0.44      0.57         9\n",
            "          16       0.71      0.77      0.74        99\n",
            "          17       0.82      0.75      0.78        12\n",
            "          18       0.81      0.65      0.72        20\n",
            "          19       0.70      0.73      0.71       133\n",
            "          20       0.62      0.53      0.57        70\n",
            "          21       0.71      0.81      0.76        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.64      0.75      0.69        12\n",
            "          24       0.62      0.53      0.57        19\n",
            "          25       0.88      0.74      0.81        31\n",
            "          26       1.00      0.88      0.93         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.43      0.30      0.35        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       1.00      0.58      0.74        12\n",
            "          31       0.78      0.54      0.64        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.50      0.45      0.48        11\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.50      0.40      0.44         5\n",
            "          40       1.00      0.20      0.33        10\n",
            "          41       0.75      0.38      0.50         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.86      1.00      0.92         6\n",
            "          44       0.67      0.80      0.73         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.81      2246\n",
            "   macro avg       0.80      0.63      0.67      2246\n",
            "weighted avg       0.82      0.81      0.81      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Linear SVC--------------------\n",
            "정확도: 0.7934105075690115\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        12\n",
            "           1       0.74      0.74      0.74       105\n",
            "           2       0.72      0.65      0.68        20\n",
            "           3       0.91      0.92      0.92       813\n",
            "           4       0.82      0.86      0.84       474\n",
            "           5       0.50      0.20      0.29         5\n",
            "           6       0.88      1.00      0.93        14\n",
            "           7       1.00      0.67      0.80         3\n",
            "           8       0.66      0.71      0.68        38\n",
            "           9       0.78      0.84      0.81        25\n",
            "          10       0.88      0.77      0.82        30\n",
            "          11       0.66      0.73      0.70        83\n",
            "          12       0.45      0.38      0.42        13\n",
            "          13       0.59      0.51      0.55        37\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.56      0.56      0.56         9\n",
            "          16       0.65      0.73      0.69        99\n",
            "          17       0.71      0.42      0.53        12\n",
            "          18       0.81      0.65      0.72        20\n",
            "          19       0.60      0.65      0.63       133\n",
            "          20       0.55      0.46      0.50        70\n",
            "          21       0.63      0.81      0.71        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.67      0.67      0.67        12\n",
            "          24       0.55      0.58      0.56        19\n",
            "          25       0.88      0.71      0.79        31\n",
            "          26       0.88      0.88      0.88         8\n",
            "          27       0.67      0.50      0.57         4\n",
            "          28       0.67      0.40      0.50        10\n",
            "          29       0.33      0.75      0.46         4\n",
            "          30       0.71      0.42      0.53        12\n",
            "          31       0.67      0.46      0.55        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.83      1.00      0.91         5\n",
            "          34       0.67      0.57      0.62         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.67      0.55      0.60        11\n",
            "          37       0.40      1.00      0.57         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       1.00      0.60      0.75         5\n",
            "          40       0.67      0.20      0.31        10\n",
            "          41       0.67      0.50      0.57         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.75      1.00      0.86         6\n",
            "          44       0.57      0.80      0.67         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.79      2246\n",
            "   macro avg       0.74      0.65      0.66      2246\n",
            "weighted avg       0.80      0.79      0.79      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Voting Classifier--------------------\n",
            "정확도: 0.798753339269813\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        12\n",
            "           1       0.77      0.74      0.76       105\n",
            "           2       0.68      0.75      0.71        20\n",
            "           3       0.90      0.93      0.92       813\n",
            "           4       0.77      0.89      0.83       474\n",
            "           5       0.50      0.20      0.29         5\n",
            "           6       0.91      0.71      0.80        14\n",
            "           7       0.25      0.33      0.29         3\n",
            "           8       0.70      0.68      0.69        38\n",
            "           9       0.95      0.80      0.87        25\n",
            "          10       0.83      0.83      0.83        30\n",
            "          11       0.69      0.72      0.71        83\n",
            "          12       0.50      0.46      0.48        13\n",
            "          13       0.65      0.54      0.59        37\n",
            "          14       0.14      0.50      0.22         2\n",
            "          15       0.38      0.33      0.35         9\n",
            "          16       0.76      0.73      0.74        99\n",
            "          17       0.62      0.42      0.50        12\n",
            "          18       0.71      0.50      0.59        20\n",
            "          19       0.75      0.71      0.73       133\n",
            "          20       0.75      0.47      0.58        70\n",
            "          21       0.69      0.67      0.68        27\n",
            "          22       0.33      0.14      0.20         7\n",
            "          23       0.67      0.67      0.67        12\n",
            "          24       0.71      0.53      0.61        19\n",
            "          25       0.88      0.68      0.76        31\n",
            "          26       0.75      0.75      0.75         8\n",
            "          27       1.00      0.50      0.67         4\n",
            "          28       0.40      0.20      0.27        10\n",
            "          29       0.38      0.75      0.50         4\n",
            "          30       0.45      0.42      0.43        12\n",
            "          31       0.67      0.46      0.55        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.71      1.00      0.83         5\n",
            "          34       1.00      0.57      0.73         7\n",
            "          35       0.33      0.17      0.22         6\n",
            "          36       0.50      0.55      0.52        11\n",
            "          37       0.50      1.00      0.67         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.67      0.40      0.50         5\n",
            "          40       1.00      0.40      0.57        10\n",
            "          41       0.50      0.62      0.56         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.75      0.50      0.60         6\n",
            "          44       0.57      0.80      0.67         5\n",
            "          45       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.80      2246\n",
            "   macro avg       0.66      0.60      0.60      2246\n",
            "weighted avg       0.80      0.80      0.79      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_models(num_words=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKS0qN2aomMZ",
        "outputId": "54e512ff-b2c8-4272-ec51-5d2fe0eeee85"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Logistic Regression--------------------\n",
            "Logistic Regression 정확도: 0.8161175422974176\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.75      0.79      0.77       105\n",
            "           2       0.78      0.70      0.74        20\n",
            "           3       0.92      0.93      0.93       813\n",
            "           4       0.81      0.88      0.84       474\n",
            "           5       1.00      0.20      0.33         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.71      0.71      0.71        38\n",
            "           9       0.85      0.88      0.86        25\n",
            "          10       0.93      0.90      0.92        30\n",
            "          11       0.67      0.72      0.70        83\n",
            "          12       0.57      0.31      0.40        13\n",
            "          13       0.64      0.62      0.63        37\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.80      0.44      0.57         9\n",
            "          16       0.70      0.77      0.73        99\n",
            "          17       0.82      0.75      0.78        12\n",
            "          18       0.76      0.65      0.70        20\n",
            "          19       0.69      0.73      0.71       133\n",
            "          20       0.64      0.53      0.58        70\n",
            "          21       0.69      0.81      0.75        27\n",
            "          22       1.00      0.14      0.25         7\n",
            "          23       0.64      0.75      0.69        12\n",
            "          24       0.62      0.53      0.57        19\n",
            "          25       0.89      0.77      0.83        31\n",
            "          26       1.00      0.88      0.93         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.50      0.30      0.37        10\n",
            "          29       0.57      1.00      0.73         4\n",
            "          30       1.00      0.67      0.80        12\n",
            "          31       0.78      0.54      0.64        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.44      0.36      0.40        11\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.50      0.40      0.44         5\n",
            "          40       1.00      0.20      0.33        10\n",
            "          41       0.75      0.38      0.50         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.86      1.00      0.92         6\n",
            "          44       0.67      0.80      0.73         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.82      2246\n",
            "   macro avg       0.78      0.64      0.67      2246\n",
            "weighted avg       0.82      0.82      0.81      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Linear SVC--------------------\n",
            "정확도: 0.7916295636687445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.67      0.73        12\n",
            "           1       0.71      0.76      0.74       105\n",
            "           2       0.75      0.75      0.75        20\n",
            "           3       0.91      0.92      0.91       813\n",
            "           4       0.81      0.84      0.82       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.93      0.93      0.93        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.62      0.68      0.65        38\n",
            "           9       0.81      0.84      0.82        25\n",
            "          10       0.92      0.77      0.84        30\n",
            "          11       0.66      0.73      0.69        83\n",
            "          12       0.38      0.38      0.38        13\n",
            "          13       0.59      0.59      0.59        37\n",
            "          14       0.50      1.00      0.67         2\n",
            "          15       0.67      0.44      0.53         9\n",
            "          16       0.67      0.72      0.69        99\n",
            "          17       0.71      0.42      0.53        12\n",
            "          18       0.80      0.60      0.69        20\n",
            "          19       0.64      0.67      0.65       133\n",
            "          20       0.57      0.49      0.52        70\n",
            "          21       0.62      0.85      0.72        27\n",
            "          22       0.50      0.14      0.22         7\n",
            "          23       0.67      0.67      0.67        12\n",
            "          24       0.73      0.58      0.65        19\n",
            "          25       0.85      0.71      0.77        31\n",
            "          26       0.88      0.88      0.88         8\n",
            "          27       0.67      0.50      0.57         4\n",
            "          28       0.40      0.40      0.40        10\n",
            "          29       0.33      0.75      0.46         4\n",
            "          30       0.83      0.42      0.56        12\n",
            "          31       0.88      0.54      0.67        13\n",
            "          32       1.00      1.00      1.00        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.33      0.27      0.30        11\n",
            "          37       0.50      0.50      0.50         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.40      0.40      0.40         5\n",
            "          40       1.00      0.20      0.33        10\n",
            "          41       0.83      0.62      0.71         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.67      1.00      0.80         6\n",
            "          44       0.57      0.80      0.67         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.79      2246\n",
            "   macro avg       0.71      0.62      0.63      2246\n",
            "weighted avg       0.79      0.79      0.79      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Voting Classifier--------------------\n",
            "정확도: 0.8000890471950134\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61        12\n",
            "           1       0.80      0.78      0.79       105\n",
            "           2       0.67      0.70      0.68        20\n",
            "           3       0.91      0.93      0.92       813\n",
            "           4       0.78      0.89      0.83       474\n",
            "           5       1.00      0.20      0.33         5\n",
            "           6       0.77      0.71      0.74        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.67      0.68      0.68        38\n",
            "           9       0.95      0.80      0.87        25\n",
            "          10       0.83      0.80      0.81        30\n",
            "          11       0.68      0.71      0.69        83\n",
            "          12       0.50      0.46      0.48        13\n",
            "          13       0.65      0.59      0.62        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.25      0.11      0.15         9\n",
            "          16       0.76      0.73      0.74        99\n",
            "          17       0.83      0.42      0.56        12\n",
            "          18       0.62      0.50      0.56        20\n",
            "          19       0.75      0.69      0.72       133\n",
            "          20       0.74      0.46      0.57        70\n",
            "          21       0.64      0.67      0.65        27\n",
            "          22       0.33      0.14      0.20         7\n",
            "          23       0.62      0.67      0.64        12\n",
            "          24       0.69      0.47      0.56        19\n",
            "          25       0.88      0.68      0.76        31\n",
            "          26       1.00      1.00      1.00         8\n",
            "          27       0.33      0.50      0.40         4\n",
            "          28       0.29      0.20      0.24        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       0.36      0.42      0.38        12\n",
            "          31       0.58      0.54      0.56        13\n",
            "          32       1.00      1.00      1.00        10\n",
            "          33       0.83      1.00      0.91         5\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       0.33      0.17      0.22         6\n",
            "          36       0.54      0.64      0.58        11\n",
            "          37       0.50      1.00      0.67         2\n",
            "          38       0.50      0.33      0.40         3\n",
            "          39       0.33      0.20      0.25         5\n",
            "          40       0.75      0.30      0.43        10\n",
            "          41       0.62      0.62      0.62         8\n",
            "          42       1.00      0.67      0.80         3\n",
            "          43       0.50      0.50      0.50         6\n",
            "          44       0.80      0.80      0.80         5\n",
            "          45       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.80      2246\n",
            "   macro avg       0.65      0.59      0.60      2246\n",
            "weighted avg       0.80      0.80      0.79      2246\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델별 결과 비교\n",
        "\n",
        "| num_words | Model               | Accuracy | Macro avg. F1-score | Weighted avg. F1-score |\n",
        "|-----------|---------------------|----------|---------------------|-----------------------|\n",
        "| 10000     | Logistic Regression |    0.81     |    0.67                |   0.81                   |\n",
        "|           | Linear SVC          |    0.78     |    0.64                |   0.78                   |\n",
        "|           | Voting Classifier   |    0.80     |    0.60                |   0.79                   |\n",
        "|-----------|---------------------|----------|---------------------|-----------------------|\n",
        "| 20000     | Logistic Regression |    0.81     |    0.67                |   0.81                   |\n",
        "|           | Linear SVC          |    0.79     |    0.66                |   0.79                   |\n",
        "|           | Voting Classifier   |    0.80     |    0.60                |   0.79                   |\n",
        "|-----------|---------------------|----------|---------------------|-----------------------|\n",
        "| 30000     | Logistic Regression |    0.82     |    0.67                |   0.81                   |\n",
        "|           | Linear SVC          |    0.79     |    0.63                |   0.79                   |\n",
        "|           | Voting Classifier   |    0.80     |    0.60                |   0.79                   |\n"
      ],
      "metadata": {
        "id": "Ta0DcIvGLibJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 딥러닝 실험"
      ],
      "metadata": {
        "id": "b9E5QqDBo1CF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = load_data(num_words=10000)\n",
        "\n",
        "# print(x_train.shape, x_test.shape)\n",
        "# (8982, 9670) (2246, 9670)\n",
        "\n",
        "# TF-IDF 행렬을 3D로 변환합니다.\n",
        "x_train = np.expand_dims(x_train.toarray(), axis=-1)\n",
        "x_test = np.expand_dims(x_test.toarray(), axis=-1)\n",
        "\n",
        "# print(x_train.shape, x_test.shape)\n",
        "# (8982, 9670, 1) (2246, 9670, 1)\n",
        "\n",
        "# Conv1D 기반 Keras 모델을 생성합니다.\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))  # 드롭아웃 추가\n",
        "model.add(Dense(46, activation='softmax'))  # 46개의 클래스\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "predicted = model.predict(x_test)\n",
        "predicted = np.argmax(predicted, axis=1)\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
        "print(classification_report(y_test, predicted, zero_division=0))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "collapsed": true,
        "id": "uDxqYyldUbyQ",
        "outputId": "08caa928-5513-4c76-ee4d-b12fd783eb5b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_6 (Conv1D)           (None, 9666, 128)         768       \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 46)                5934      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6702 (26.18 KB)\n",
            "Trainable params: 6702 (26.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "(8982, 9670, 1) (8982,) (2246, 9670, 1) (2246,)\n",
            "Epoch 1/10\n",
            "281/281 [==============================] - 174s 615ms/step - loss: 2.6951 - accuracy: 0.3389 - val_loss: 2.4037 - val_accuracy: 0.3620\n",
            "Epoch 2/10\n",
            "281/281 [==============================] - 163s 581ms/step - loss: 2.4148 - accuracy: 0.3520 - val_loss: 2.4020 - val_accuracy: 0.3620\n",
            "Epoch 3/10\n",
            "281/281 [==============================] - 221s 786ms/step - loss: 2.4096 - accuracy: 0.3534 - val_loss: 2.4008 - val_accuracy: 0.3620\n",
            "Epoch 4/10\n",
            " 72/281 [======>.......................] - ETA: 1:56 - loss: 2.3897 - accuracy: 0.3559"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4238db1aab1a>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# 모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conv1D 기반 Keras 모델을 생성합니다.\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(46, activation='softmax'))  # 46개의 클래스\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "predicted = model.predict(x_test)\n",
        "predicted = np.argmax(predicted, axis=1)\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
        "print(classification_report(y_test, predicted, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "BmCfTYp-c2x6",
        "outputId": "1808ed61-a76d-489b-b691-bb9edf5ba070"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_9 (Conv1D)           (None, 9666, 128)         768       \n",
            "                                                                 \n",
            " global_max_pooling1d_7 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 46)                5934      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23214 (90.68 KB)\n",
            "Trainable params: 23214 (90.68 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "281/281 [==============================] - 186s 658ms/step - loss: 2.6051 - accuracy: 0.3267 - val_loss: 2.4058 - val_accuracy: 0.3620\n",
            "Epoch 2/10\n",
            "281/281 [==============================] - 172s 614ms/step - loss: 2.4412 - accuracy: 0.3437 - val_loss: 2.4011 - val_accuracy: 0.3620\n",
            "Epoch 3/10\n",
            "281/281 [==============================] - 176s 629ms/step - loss: 2.4279 - accuracy: 0.3526 - val_loss: 2.4059 - val_accuracy: 0.3620\n",
            "Epoch 4/10\n",
            "281/281 [==============================] - 175s 624ms/step - loss: 2.4200 - accuracy: 0.3542 - val_loss: 2.3985 - val_accuracy: 0.3624\n",
            "Epoch 5/10\n",
            "281/281 [==============================] - 183s 653ms/step - loss: 2.4115 - accuracy: 0.3536 - val_loss: 2.4013 - val_accuracy: 0.3695\n",
            "Epoch 6/10\n",
            " 12/281 [>.............................] - ETA: 2:28 - loss: 2.5392 - accuracy: 0.3385"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fee3fba0079a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Conv1D (kernel_size=60, filters=128, strides=3, padding='valid', activation='relu'))\n",
        "model.add(MaxPooling1D(1, padding = 'valid'))\n",
        "\n",
        "model.add(Conv1D(kernel_size=60, filters=64, activation='relu'))\n",
        "model.add(MaxPooling1D(1, padding = 'valid'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgEyVSw3Y1zZ",
        "outputId": "18d12161-e528-4479-97d9-5dd807ac48e3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 3204, 128)         7808      \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPoolin  (None, 3204, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 3145, 64)          491584    \n",
            "                                                                 \n",
            " max_pooling1d_10 (MaxPooli  (None, 3145, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 3145, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 3145, 64)          0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 3145, 128)         8320      \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 3145, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 3145, 128)         0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 3145, 46)          5934      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 514414 (1.96 MB)\n",
            "Trainable params: 514030 (1.96 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "predicted = model.predict(x_test)\n",
        "predicted = np.argmax(predicted, axis=1)\n",
        "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
        "print(classification_report(y_test, predicted, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "gVHHi7x7jSVd",
        "outputId": "0ef469a6-0674-4e5e-853b-87e5e5aa7aa9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-47-fb75932b1eb0>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [100640,46] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_29805]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-fb75932b1eb0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-47-fb75932b1eb0>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [100640,46] and labels shape [32]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_29805]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 왜 에러가 나는지..? 그냥 모델 구조만 조금 바꾼건데"
      ],
      "metadata": {
        "id": "1ITPqFSGlgw_"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}