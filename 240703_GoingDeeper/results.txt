num_words = 10000

--------------------Logistic Regression--------------------
Logistic Regression 정확도: 0.8107747105966162
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.74      0.78      0.76       105
           2       0.70      0.70      0.70        20
           3       0.91      0.93      0.92       813
           4       0.80      0.87      0.84       474
           5       1.00      0.20      0.33         5
           6       0.93      0.93      0.93        14
           7       1.00      0.33      0.50         3
           8       0.68      0.71      0.69        38
           9       0.81      0.88      0.85        25
          10       0.93      0.87      0.90        30
          11       0.67      0.72      0.70        83
          12       0.62      0.38      0.48        13
          13       0.65      0.59      0.62        37
          14       0.67      1.00      0.80         2
          15       0.80      0.44      0.57         9
          16       0.70      0.77      0.73        99
          17       0.80      0.67      0.73        12
          18       0.81      0.65      0.72        20
          19       0.69      0.71      0.70       133
          20       0.60      0.49      0.54        70
          21       0.71      0.81      0.76        27
          22       1.00      0.14      0.25         7
          23       0.64      0.75      0.69        12
          24       0.62      0.53      0.57        19
          25       0.88      0.68      0.76        31
          26       1.00      0.88      0.93         8
          27       1.00      0.25      0.40         4
          28       0.67      0.40      0.50        10
          29       0.50      0.75      0.60         4
          30       1.00      0.58      0.74        12
          31       0.78      0.54      0.64        13
          32       1.00      0.80      0.89        10
          33       0.80      0.80      0.80         5
          34       0.80      0.57      0.67         7
          35       1.00      0.33      0.50         6
          36       0.45      0.45      0.45        11
          37       0.50      0.50      0.50         2
          38       0.50      0.33      0.40         3
          39       0.50      0.40      0.44         5
          40       0.75      0.30      0.43        10
          41       0.75      0.38      0.50         8
          42       1.00      0.67      0.80         3
          43       0.86      1.00      0.92         6
          44       1.00      0.80      0.89         5
          45       1.00      1.00      1.00         1

    accuracy                           0.81      2246
   macro avg       0.79      0.63      0.67      2246
weighted avg       0.81      0.81      0.81      2246

--------------------------------------------------

--------------------Linear SVC--------------------
정확도: 0.7845057880676759
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.74      0.74      0.74       105
           2       0.57      0.65      0.60        20
           3       0.91      0.91      0.91       813
           4       0.80      0.84      0.82       474
           5       0.00      0.00      0.00         5
           6       0.86      0.86      0.86        14
           7       0.50      0.33      0.40         3
           8       0.66      0.71      0.68        38
           9       0.77      0.80      0.78        25
          10       0.92      0.77      0.84        30
          11       0.66      0.77      0.71        83
          12       0.38      0.38      0.38        13
          13       0.62      0.57      0.59        37
          14       0.67      1.00      0.80         2
          15       0.62      0.56      0.59         9
          16       0.62      0.71      0.66        99
          17       0.71      0.42      0.53        12
          18       0.80      0.60      0.69        20
          19       0.63      0.63      0.63       133
          20       0.51      0.41      0.46        70
          21       0.56      0.70      0.62        27
          22       0.20      0.14      0.17         7
          23       0.60      0.75      0.67        12
          24       0.69      0.58      0.63        19
          25       0.92      0.71      0.80        31
          26       0.88      0.88      0.88         8
          27       1.00      0.50      0.67         4
          28       0.57      0.40      0.47        10
          29       0.50      0.75      0.60         4
          30       0.75      0.50      0.60        12
          31       0.89      0.62      0.73        13
          32       1.00      0.90      0.95        10
          33       0.80      0.80      0.80         5
          34       0.57      0.57      0.57         7
          35       1.00      0.33      0.50         6
          36       0.62      0.45      0.53        11
          37       0.67      1.00      0.80         2
          38       1.00      0.33      0.50         3
          39       0.75      0.60      0.67         5
          40       0.25      0.20      0.22        10
          41       0.83      0.62      0.71         8
          42       1.00      0.33      0.50         3
          43       0.55      1.00      0.71         6
          44       0.80      0.80      0.80         5
          45       1.00      1.00      1.00         1

    accuracy                           0.78      2246
   macro avg       0.70      0.63      0.64      2246
weighted avg       0.79      0.78      0.78      2246

---------------------------------------------------------

--------------------Voting Classifier--------------------
정확도: 0.7969723953695459
              precision    recall  f1-score   support

           0       0.82      0.75      0.78        12
           1       0.76      0.72      0.74       105
           2       0.78      0.70      0.74        20
           3       0.91      0.93      0.92       813
           4       0.78      0.88      0.82       474
           5       0.00      0.00      0.00         5
           6       0.80      0.86      0.83        14
           7       1.00      0.33      0.50         3
           8       0.69      0.66      0.68        38
           9       0.81      0.84      0.82        25
          10       0.90      0.87      0.88        30
          11       0.66      0.71      0.68        83
          12       0.33      0.46      0.39        13
          13       0.71      0.65      0.68        37
          14       0.14      0.50      0.22         2
          15       0.43      0.33      0.38         9
          16       0.78      0.76      0.77        99
          17       0.33      0.33      0.33        12
          18       0.67      0.50      0.57        20
          19       0.71      0.69      0.70       133
          20       0.72      0.47      0.57        70
          21       0.71      0.81      0.76        27
          22       1.00      0.14      0.25         7
          23       0.54      0.58      0.56        12
          24       0.63      0.63      0.63        19
          25       0.95      0.58      0.72        31
          26       0.75      0.75      0.75         8
          27       0.50      0.50      0.50         4
          28       0.43      0.30      0.35        10
          29       0.25      0.75      0.38         4
          30       0.50      0.42      0.45        12
          31       0.83      0.38      0.53        13
          32       1.00      0.90      0.95        10
          33       0.75      0.60      0.67         5
          34       1.00      0.57      0.73         7
          35       1.00      0.67      0.80         6
          36       0.62      0.45      0.53        11
          37       0.67      1.00      0.80         2
          38       0.50      0.33      0.40         3
          39       0.67      0.40      0.50         5
          40       0.50      0.10      0.17        10
          41       0.62      0.62      0.62         8
          42       0.67      0.67      0.67         3
          43       0.67      0.67      0.67         6
          44       0.67      0.80      0.73         5
          45       0.33      1.00      0.50         1

    accuracy                           0.80      2246
   macro avg       0.66      0.60      0.60      2246
weighted avg       0.80      0.80      0.79      2246

-----------------------------------------------------------


num_words = 20000

--------------------Logistic Regression--------------------
Logistic Regression 정확도: 0.8147818343722173
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.73      0.79      0.76       105
           2       0.78      0.70      0.74        20
           3       0.92      0.93      0.92       813
           4       0.80      0.88      0.84       474
           5       1.00      0.20      0.33         5
           6       0.93      0.93      0.93        14
           7       1.00      0.33      0.50         3
           8       0.69      0.71      0.70        38
           9       0.85      0.88      0.86        25
          10       0.96      0.87      0.91        30
          11       0.68      0.72      0.70        83
          12       0.62      0.38      0.48        13
          13       0.65      0.65      0.65        37
          14       0.67      1.00      0.80         2
          15       0.80      0.44      0.57         9
          16       0.71      0.77      0.74        99
          17       0.82      0.75      0.78        12
          18       0.81      0.65      0.72        20
          19       0.70      0.73      0.71       133
          20       0.62      0.53      0.57        70
          21       0.71      0.81      0.76        27
          22       1.00      0.14      0.25         7
          23       0.64      0.75      0.69        12
          24       0.62      0.53      0.57        19
          25       0.88      0.74      0.81        31
          26       1.00      0.88      0.93         8
          27       1.00      0.25      0.40         4
          28       0.43      0.30      0.35        10
          29       0.50      0.75      0.60         4
          30       1.00      0.58      0.74        12
          31       0.78      0.54      0.64        13
          32       1.00      0.80      0.89        10
          33       0.80      0.80      0.80         5
          34       0.80      0.57      0.67         7
          35       1.00      0.33      0.50         6
          36       0.50      0.45      0.48        11
          37       0.50      0.50      0.50         2
          38       1.00      0.33      0.50         3
          39       0.50      0.40      0.44         5
          40       1.00      0.20      0.33        10
          41       0.75      0.38      0.50         8
          42       1.00      0.67      0.80         3
          43       0.86      1.00      0.92         6
          44       0.67      0.80      0.73         5
          45       1.00      1.00      1.00         1

    accuracy                           0.81      2246
   macro avg       0.80      0.63      0.67      2246
weighted avg       0.82      0.81      0.81      2246

--------------------------------------------------

--------------------Linear SVC--------------------
정확도: 0.7934105075690115
              precision    recall  f1-score   support

           0       0.80      0.67      0.73        12
           1       0.74      0.74      0.74       105
           2       0.72      0.65      0.68        20
           3       0.91      0.92      0.92       813
           4       0.82      0.86      0.84       474
           5       0.50      0.20      0.29         5
           6       0.88      1.00      0.93        14
           7       1.00      0.67      0.80         3
           8       0.66      0.71      0.68        38
           9       0.78      0.84      0.81        25
          10       0.88      0.77      0.82        30
          11       0.66      0.73      0.70        83
          12       0.45      0.38      0.42        13
          13       0.59      0.51      0.55        37
          14       0.67      1.00      0.80         2
          15       0.56      0.56      0.56         9
          16       0.65      0.73      0.69        99
          17       0.71      0.42      0.53        12
          18       0.81      0.65      0.72        20
          19       0.60      0.65      0.63       133
          20       0.55      0.46      0.50        70
          21       0.63      0.81      0.71        27
          22       1.00      0.14      0.25         7
          23       0.67      0.67      0.67        12
          24       0.55      0.58      0.56        19
          25       0.88      0.71      0.79        31
          26       0.88      0.88      0.88         8
          27       0.67      0.50      0.57         4
          28       0.67      0.40      0.50        10
          29       0.33      0.75      0.46         4
          30       0.71      0.42      0.53        12
          31       0.67      0.46      0.55        13
          32       1.00      0.80      0.89        10
          33       0.83      1.00      0.91         5
          34       0.67      0.57      0.62         7
          35       1.00      0.33      0.50         6
          36       0.67      0.55      0.60        11
          37       0.40      1.00      0.57         2
          38       1.00      0.33      0.50         3
          39       1.00      0.60      0.75         5
          40       0.67      0.20      0.31        10
          41       0.67      0.50      0.57         8
          42       1.00      0.67      0.80         3
          43       0.75      1.00      0.86         6
          44       0.57      0.80      0.67         5
          45       1.00      1.00      1.00         1

    accuracy                           0.79      2246
   macro avg       0.74      0.65      0.66      2246
weighted avg       0.80      0.79      0.79      2246

---------------------------------------------------------

--------------------Voting Classifier--------------------
정확도: 0.798753339269813
              precision    recall  f1-score   support

           0       0.80      0.67      0.73        12
           1       0.77      0.74      0.76       105
           2       0.68      0.75      0.71        20
           3       0.90      0.93      0.92       813
           4       0.77      0.89      0.83       474
           5       0.50      0.20      0.29         5
           6       0.91      0.71      0.80        14
           7       0.25      0.33      0.29         3
           8       0.70      0.68      0.69        38
           9       0.95      0.80      0.87        25
          10       0.83      0.83      0.83        30
          11       0.69      0.72      0.71        83
          12       0.50      0.46      0.48        13
          13       0.65      0.54      0.59        37
          14       0.14      0.50      0.22         2
          15       0.38      0.33      0.35         9
          16       0.76      0.73      0.74        99
          17       0.62      0.42      0.50        12
          18       0.71      0.50      0.59        20
          19       0.75      0.71      0.73       133
          20       0.75      0.47      0.58        70
          21       0.69      0.67      0.68        27
          22       0.33      0.14      0.20         7
          23       0.67      0.67      0.67        12
          24       0.71      0.53      0.61        19
          25       0.88      0.68      0.76        31
          26       0.75      0.75      0.75         8
          27       1.00      0.50      0.67         4
          28       0.40      0.20      0.27        10
          29       0.38      0.75      0.50         4
          30       0.45      0.42      0.43        12
          31       0.67      0.46      0.55        13
          32       1.00      0.80      0.89        10
          33       0.71      1.00      0.83         5
          34       1.00      0.57      0.73         7
          35       0.33      0.17      0.22         6
          36       0.50      0.55      0.52        11
          37       0.50      1.00      0.67         2
          38       0.50      0.33      0.40         3
          39       0.67      0.40      0.50         5
          40       1.00      0.40      0.57        10
          41       0.50      0.62      0.56         8
          42       1.00      0.67      0.80         3
          43       0.75      0.50      0.60         6
          44       0.57      0.80      0.67         5
          45       0.33      1.00      0.50         1

    accuracy                           0.80      2246
   macro avg       0.66      0.60      0.60      2246
weighted avg       0.80      0.80      0.79      2246

-----------------------------------------------------

num_words = None

--------------------Logistic Regression--------------
Logistic Regression 정확도: 0.8161175422974176
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.75      0.79      0.77       105
           2       0.78      0.70      0.74        20
           3       0.92      0.93      0.93       813
           4       0.81      0.88      0.84       474
           5       1.00      0.20      0.33         5
           6       0.93      0.93      0.93        14
           7       1.00      0.33      0.50         3
           8       0.71      0.71      0.71        38
           9       0.85      0.88      0.86        25
          10       0.93      0.90      0.92        30
          11       0.67      0.72      0.70        83
          12       0.57      0.31      0.40        13
          13       0.64      0.62      0.63        37
          14       0.67      1.00      0.80         2
          15       0.80      0.44      0.57         9
          16       0.70      0.77      0.73        99
          17       0.82      0.75      0.78        12
          18       0.76      0.65      0.70        20
          19       0.69      0.73      0.71       133
          20       0.64      0.53      0.58        70
          21       0.69      0.81      0.75        27
          22       1.00      0.14      0.25         7
          23       0.64      0.75      0.69        12
          24       0.62      0.53      0.57        19
          25       0.89      0.77      0.83        31
          26       1.00      0.88      0.93         8
          27       1.00      0.25      0.40         4
          28       0.50      0.30      0.37        10
          29       0.57      1.00      0.73         4
          30       1.00      0.67      0.80        12
          31       0.78      0.54      0.64        13
          32       1.00      0.80      0.89        10
          33       0.80      0.80      0.80         5
          34       0.80      0.57      0.67         7
          35       1.00      0.33      0.50         6
          36       0.44      0.36      0.40        11
          37       0.50      0.50      0.50         2
          38       0.50      0.33      0.40         3
          39       0.50      0.40      0.44         5
          40       1.00      0.20      0.33        10
          41       0.75      0.38      0.50         8
          42       1.00      0.67      0.80         3
          43       0.86      1.00      0.92         6
          44       0.67      0.80      0.73         5
          45       1.00      1.00      1.00         1

    accuracy                           0.82      2246
   macro avg       0.78      0.64      0.67      2246
weighted avg       0.82      0.82      0.81      2246

--------------------------------------------------

/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
--------------------Linear SVC--------------------
정확도: 0.7916295636687445
              precision    recall  f1-score   support

           0       0.80      0.67      0.73        12
           1       0.71      0.76      0.74       105
           2       0.75      0.75      0.75        20
           3       0.91      0.92      0.91       813
           4       0.81      0.84      0.82       474
           5       0.00      0.00      0.00         5
           6       0.93      0.93      0.93        14
           7       1.00      0.33      0.50         3
           8       0.62      0.68      0.65        38
           9       0.81      0.84      0.82        25
          10       0.92      0.77      0.84        30
          11       0.66      0.73      0.69        83
          12       0.38      0.38      0.38        13
          13       0.59      0.59      0.59        37
          14       0.50      1.00      0.67         2
          15       0.67      0.44      0.53         9
          16       0.67      0.72      0.69        99
          17       0.71      0.42      0.53        12
          18       0.80      0.60      0.69        20
          19       0.64      0.67      0.65       133
          20       0.57      0.49      0.52        70
          21       0.62      0.85      0.72        27
          22       0.50      0.14      0.22         7
          23       0.67      0.67      0.67        12
          24       0.73      0.58      0.65        19
          25       0.85      0.71      0.77        31
          26       0.88      0.88      0.88         8
          27       0.67      0.50      0.57         4
          28       0.40      0.40      0.40        10
          29       0.33      0.75      0.46         4
          30       0.83      0.42      0.56        12
          31       0.88      0.54      0.67        13
          32       1.00      1.00      1.00        10
          33       0.80      0.80      0.80         5
          34       0.80      0.57      0.67         7
          35       1.00      0.33      0.50         6
          36       0.33      0.27      0.30        11
          37       0.50      0.50      0.50         2
          38       1.00      0.33      0.50         3
          39       0.40      0.40      0.40         5
          40       1.00      0.20      0.33        10
          41       0.83      0.62      0.71         8
          42       1.00      0.67      0.80         3
          43       0.67      1.00      0.80         6
          44       0.57      0.80      0.67         5
          45       1.00      1.00      1.00         1

    accuracy                           0.79      2246
   macro avg       0.71      0.62      0.63      2246
weighted avg       0.79      0.79      0.79      2246

---------------------------------------------------------


--------------------Voting Classifier--------------------
정확도: 0.8000890471950134
              precision    recall  f1-score   support

           0       0.64      0.58      0.61        12
           1       0.80      0.78      0.79       105
           2       0.67      0.70      0.68        20
           3       0.91      0.93      0.92       813
           4       0.78      0.89      0.83       474
           5       1.00      0.20      0.33         5
           6       0.77      0.71      0.74        14
           7       1.00      0.33      0.50         3
           8       0.67      0.68      0.68        38
           9       0.95      0.80      0.87        25
          10       0.83      0.80      0.81        30
          11       0.68      0.71      0.69        83
          12       0.50      0.46      0.48        13
          13       0.65      0.59      0.62        37
          14       0.00      0.00      0.00         2
          15       0.25      0.11      0.15         9
          16       0.76      0.73      0.74        99
          17       0.83      0.42      0.56        12
          18       0.62      0.50      0.56        20
          19       0.75      0.69      0.72       133
          20       0.74      0.46      0.57        70
          21       0.64      0.67      0.65        27
          22       0.33      0.14      0.20         7
          23       0.62      0.67      0.64        12
          24       0.69      0.47      0.56        19
          25       0.88      0.68      0.76        31
          26       1.00      1.00      1.00         8
          27       0.33      0.50      0.40         4
          28       0.29      0.20      0.24        10
          29       0.50      0.75      0.60         4
          30       0.36      0.42      0.38        12
          31       0.58      0.54      0.56        13
          32       1.00      1.00      1.00        10
          33       0.83      1.00      0.91         5
          34       0.80      0.57      0.67         7
          35       0.33      0.17      0.22         6
          36       0.54      0.64      0.58        11
          37       0.50      1.00      0.67         2
          38       0.50      0.33      0.40         3
          39       0.33      0.20      0.25         5
          40       0.75      0.30      0.43        10
          41       0.62      0.62      0.62         8
          42       1.00      0.67      0.80         3
          43       0.50      0.50      0.50         6
          44       0.80      0.80      0.80         5
          45       0.50      1.00      0.67         1

    accuracy                           0.80      2246
   macro avg       0.65      0.59      0.60      2246
weighted avg       0.80      0.80      0.79      2246

------------------------------------------------------------

